# 9. Security

This chapter covers the security mechanisms implemented in ProzChain's transaction layer to prevent attacks, maintain integrity, and ensure reliability.

## 9.1 Transaction Replay Protection

```rust
struct ReplayProtection {
    /// State view for nonce checking
    state_view: Arc<StateView>,
    
    /// Chain ID for cross-chain protection
    chain_id: u64,
    
    /// Recent blocks for receipt validation
    recent_blocks: Arc<RecentBlocksCache>,
    
    /// Configuration
    config: ReplayProtectionConfig,
}

struct ReplayProtectionConfig {
    /// Whether to validate chain ID in transactions
    validate_chain_id: bool,
    
    /// Whether to use strict nonce ordering
    strict_nonce_ordering: bool,
    
    /// How long to keep transaction records for replay detection
    transaction_record_expiry: Duration,
    
    /// Maximum allowed nonce gap
    max_nonce_gap: u64,
}

impl ReplayProtection {
    /// Check if a transaction can be safely processed without replay risk
    fn check_transaction(&self, tx: &Transaction) -> ReplayCheckResult {
        // Step 1: Check chain ID (if applicable)
        if self.config.validate_chain_id && tx.chain_id != self.chain_id {
            return ReplayCheckResult::InvalidChainId {
                expected: self.chain_id,
                actual: tx.chain_id,
            };
        }
        
        // Step 2: Check nonce
        let account_nonce = match self.state_view.get_account_nonce(&tx.sender) {
            Ok(nonce) => nonce,
            Err(_) => 0, // New account
        };
        
        // Nonce must be at least the current account nonce
        if tx.nonce < account_nonce {
            return ReplayCheckResult::NonceTooLow {
                expected: account_nonce,
                actual: tx.nonce,
            };
        }
        
        // Check nonce gap if strict ordering is required
        if self.config.strict_nonce_ordering && tx.nonce > account_nonce + self.config.max_nonce_gap {
            return ReplayCheckResult::NonceGapTooLarge {
                current: account_nonce,
                provided: tx.nonce,
                max_gap: self.config.max_nonce_gap,
            };
        }
        
        // Step 3: Check if transaction has already been processed
        if self.transaction_already_processed(tx) {
            return ReplayCheckResult::TransactionAlreadyProcessed;
        }
        
        // All checks passed
        ReplayCheckResult::Safe
    }
    
    /// Check if a transaction has already been processed
    fn transaction_already_processed(&self, tx: &Transaction) -> bool {
        // First check if transaction hash exists in any recent blocks
        if self.recent_blocks.contains_transaction(&tx.hash) {
            return true;
        }
        
        // If the hash isn't found, we need to check for semantic equivalence
        // to handle transaction malleability
        
        // In a real implementation, this would check transaction contents
        // across recent blocks
        false
    }
    
    /// Record a processed transaction to prevent future replay
    fn record_processed_transaction(&mut self, tx: &Transaction, block_hash: Hash256) {
        // In a real implementation, this would update a persistent store
        // For this example, we rely on the recent blocks cache
    }
}

enum ReplayCheckResult {
    /// Transaction is safe to process
    Safe,
    
    /// Invalid chain ID
    InvalidChainId {
        expected: u64,
        actual: u64,
    },
    
    /// Nonce too low (transaction already processed)
    NonceTooLow {
        expected: u64,
        actual: u64,
    },
    
    /// Nonce gap too large
    NonceGapTooLarge {
        current: u64,
        provided: u64,
        max_gap: u64,
    },
    
    /// Transaction has already been processed
    TransactionAlreadyProcessed,
}
```

**Design Rationale**:
- **Multi-Layer Protection**: Combines nonce verification, chain ID validation, and transaction history
- **Configurable Strictness**: Adjustable policies for different security needs
- **Semantic Equivalence**: Looks beyond just transaction hashes to prevent malleability attacks
- **Performance Optimized**: Quick rejection of invalid transactions

**For Beginners**: Transaction replay protection is like preventing someone from depositing the same check twice. The nonce is like a check number that must always increase, so an attacker can't copy a valid transaction and submit it again. Chain ID validation ensures transactions intended for one blockchain (like a test network) can't be replayed on another (like the main network).

## 9.2 Malleability Prevention

```rust
struct MalleabilityProtection {
    /// Verification methods for transaction integrity
    verification_methods: Vec<Box<dyn MalleabilityVerifier>>,
    
    /// Configuration
    config: MalleabilityConfig,
}

struct MalleabilityConfig {
    /// Whether to use strict signature format verification
    strict_signature_format: bool,
    
    /// Whether to enforce canonical signature encoding
    require_canonical_signatures: bool,
    
    /// Whether to validate transaction hash computation
    validate_hash_computation: bool,
}

trait MalleabilityVerifier: Send + Sync {
    fn verify(&self, tx: &Transaction) -> Result<(), MalleabilityError>;
}

struct SignatureFormatVerifier {
    strict_mode: bool,
}

struct HashConsistencyVerifier {}

struct CanonicalEncodingVerifier {}

enum MalleabilityError {
    InvalidSignature(String),
    NonCanonicalEncoding(String),
    InconsistentHash,
    InvalidDataEncoding(String),
}

impl MalleabilityProtection {
    fn new(config: MalleabilityConfig) -> Self {
        let mut verifiers: Vec<Box<dyn MalleabilityVerifier>> = Vec::new();
        
        // Add signature format verifier
        verifiers.push(Box::new(SignatureFormatVerifier {
            strict_mode: config.strict_signature_format,
        }));
        
        // Add hash consistency verifier if enabled
        if config.validate_hash_computation {
            verifiers.push(Box::new(HashConsistencyVerifier {}));
        }
        
        // Add canonical encoding verifier if enabled
        if config.require_canonical_signatures {
            verifiers.push(Box::new(CanonicalEncodingVerifier {}));
        }
        
        MalleabilityProtection {
            verification_methods: verifiers,
            config,
        }
    }
    
    fn verify_transaction(&self, tx: &Transaction) -> Result<(), MalleabilityError> {
        // Run all verification methods
        for verifier in &self.verification_methods {
            verifier.verify(tx)?;
        }
        
        Ok(())
    }
}

impl MalleabilityVerifier for SignatureFormatVerifier {
    fn verify(&self, tx: &Transaction) -> Result<(), MalleabilityError> {
        // Verify signature is in correct format
        let sig = &tx.signature;
        
        // Check s value is in lower half of curve order (prevents signature malleability)
        if self.strict_mode && !sig.is_s_low_value() {
            return Err(MalleabilityError::InvalidSignature(
                "Signature S value must be in lower half of curve order".into()
            ));
        }
        
        // Verify v value is valid
        if !sig.is_valid_v_value() {
            return Err(MalleabilityError::InvalidSignature(
                "Invalid signature recovery value".into()
            ));
        }
        
        Ok(())
    }
}

impl MalleabilityVerifier for HashConsistencyVerifier {
    fn verify(&self, tx: &Transaction) -> Result<(), MalleabilityError> {
        // Recompute transaction hash and verify it matches the stored hash
        let computed_hash = tx.compute_hash();
        
        if computed_hash != tx.hash {
            return Err(MalleabilityError::InconsistentHash);
        }
        
        Ok(())
    }
}

impl MalleabilityVerifier for CanonicalEncodingVerifier {
    fn verify(&self, tx: &Transaction) -> Result<(), MalleabilityError> {
        // Check if the transaction uses canonical encoding for all fields
        
        // Verify signature is in canonical form
        if !tx.signature.is_canonical_encoding() {
            return Err(MalleabilityError::NonCanonicalEncoding(
                "Signature is not in canonical form".into()
            ));
        }
        
        // Verify data field uses canonical encoding if present
        if !tx.data.is_empty() && !is_canonical_rlp_encoding(&tx.data) {
            return Err(MalleabilityError::InvalidDataEncoding(
                "Transaction data is not canonically encoded".into()
            ));
        }
        
        Ok(())
    }
}

fn is_canonical_rlp_encoding(data: &[u8]) -> bool {
    // Simplified implementation - would perform actual RLP canonical encoding checks
    true
}
```

**Design Rationale**:
- **Multiple Verification Methods**: Defends against different types of malleability
- **Strict Signature Requirements**: Enforces standardized, non-malleable signatures
- **Hash Consistency Checks**: Ensures transaction hashes are properly computed
- **Canonical Encoding**: Prevents alternate encodings of the same transaction

**For Beginners**: Transaction malleability is like someone altering a check after you've signed it, but in ways that don't invalidate your signature. This could make transaction tracking difficult or enable attacks. To prevent this, ProzChain enforces strict rules about how transactions must be formatted and signed, ensuring there's only one valid way to represent each transaction.

## 9.3 Denial of Service Mitigation

```rust
struct DoSProtection {
    /// Rate limiters keyed by client IP/identifier
    rate_limiters: RwLock<HashMap<ClientId, RateLimiter>>,
    
    /// Complexity analyzers for transactions
    complexity_analyzers: Vec<Box<dyn ComplexityAnalyzer>>,
    
    /// Configuration
    config: DoSConfig,
    
    /// Collection of banned clients
    banned_clients: RwLock<HashSet<ClientId>>,
}

struct DoSConfig {
    /// Maximum number of transactions per second per client
    max_tx_per_second: u32,
    
    /// Maximum number of concurrent requests per client
    max_concurrent_requests: u32,
    
    /// Maximum transaction complexity score allowed
    max_complexity: u64,
    
    /// Whether to enable dynamic rate limiting
    dynamic_rate_limiting: bool,
    
    /// Burst allowance factor (multiplier on base rate limit)
    burst_factor: f64,
    
    /// Ban threshold for repeated violations
    ban_threshold: u32,
    
    /// Ban duration when threshold is reached
    ban_duration: Duration,
}

struct RateLimiter {
    /// Client identifier
    client_id: ClientId,
    
    /// Token bucket for overall requests
    request_bucket: TokenBucket,
    
    /// Token bucket specifically for transactions
    transaction_bucket: TokenBucket,
    
    /// Current number of concurrent requests
    concurrent_requests: AtomicU32,
    
    /// Violation counter
    violations: AtomicU32,
    
    /// When this limiter was last used
    last_used: AtomicTime,
    
    /// Rate limit adjustment based on reputation
    reputation_factor: AtomicF64,
}

struct TokenBucket {
    /// Current number of tokens
    tokens: AtomicF64,
    
    /// Maximum capacity
    capacity: f64,
    
    /// Refill rate per second
    refill_rate: f64,
    
    /// Last refill timestamp
    last_refill: AtomicTime,
}

trait ComplexityAnalyzer: Send + Sync {
    /// Calculate complexity score for a transaction
    fn calculate_complexity(&self, tx: &Transaction) -> u64;
    
    /// Complexity type identifier
    fn complexity_type(&self) -> &'static str;
}

struct GasComplexityAnalyzer;
struct DataSizeComplexityAnalyzer;
struct ContractCodeComplexityAnalyzer;

impl DoSProtection {
    fn check_transaction(&self, tx: &Transaction, client: &ClientId) -> Result<(), DoSError> {
        // Step 1: Check if client is banned
        if self.is_client_banned(client) {
            return Err(DoSError::ClientBanned);
        }
        
        // Step 2: Check rate limits
        self.check_rate_limits(client, RequestType::Transaction)?;
        
        // Step 3: Check transaction complexity
        self.check_transaction_complexity(tx)?;
        
        // All checks passed
        Ok(())
    }
    
    fn check_rate_limits(&self, client: &ClientId, request_type: RequestType) -> Result<(), DoSError> {
        // Get or create rate limiter for this client
        let mut rate_limiters = self.rate_limiters.write().unwrap();
        let rate_limiter = rate_limiters
            .entry(client.clone())
            .or_insert_with(|| self.create_rate_limiter(client));
        
        // Check concurrent request limit
        let concurrent = rate_limiter.concurrent_requests.fetch_add(1, Ordering::SeqCst);
        if concurrent >= self.config.max_concurrent_requests {
            rate_limiter.concurrent_requests.fetch_sub(1, Ordering::SeqCst);
            return Err(DoSError::ConcurrentRequestLimitExceeded);
        }
        
        // Update last_used time
        rate_limiter.last_used.store(current_time(), Ordering::SeqCst);
        
        // Check general request rate limit
        if !rate_limiter.request_bucket.consume(1.0) {
            rate_limiter.concurrent_requests.fetch_sub(1, Ordering::SeqCst);
            rate_limiter.violations.fetch_add(1, Ordering::SeqCst);
            
            // Check if ban threshold is reached
            if rate_limiter.violations.load(Ordering::SeqCst) >= self.config.ban_threshold {
                self.ban_client(client);
            }
            
            return Err(DoSError::RateLimitExceeded);
        }
        
        // For transaction requests, also check transaction-specific rate limit
        if request_type == RequestType::Transaction {
            if !rate_limiter.transaction_bucket.consume(1.0) {
                rate_limiter.concurrent_requests.fetch_sub(1, Ordering::SeqCst);
                return Err(DoSError::TransactionRateLimitExceeded);
            }
        }
        
        Ok(())
    }
    
    fn check_transaction_complexity(&self, tx: &Transaction) -> Result<(), DoSError> {
        // Calculate overall complexity score using all analyzers
        let mut total_complexity = 0;
        
        for analyzer in &self.complexity_analyzers {
            let score = analyzer.calculate_complexity(tx);
            
            // Check if any individual score exceeds maximum
            if score > self.config.max_complexity {
                return Err(DoSError::TransactionTooComplex {
                    complexity_type: analyzer.complexity_type().to_string(),
                    score,
                    max_allowed: self.config.max_complexity,
                });
            }
            
            total_complexity += score;
        }
        
        // Check if combined score exceeds maximum
        if total_complexity > self.config.max_complexity {
            return Err(DoSError::TransactionTooComplex {
                complexity_type: "combined".to_string(),
                score: total_complexity,
                max_allowed: self.config.max_complexity,
            });
        }
        
        Ok(())
    }
    
    fn create_rate_limiter(&self, client: &ClientId) -> RateLimiter {
        let now = current_time();
        
        // Create token buckets with configured limits
        let request_bucket = TokenBucket {
            tokens: AtomicF64::new(self.config.max_concurrent_requests as f64),
            capacity: self.config.max_concurrent_requests as f64,
            refill_rate: self.config.max_concurrent_requests as f64,
            last_refill: AtomicTime::new(now),
        };
        
        let tx_bucket = TokenBucket {
            tokens: AtomicF64::new(self.config.max_tx_per_second as f64),
            capacity: self.config.max_tx_per_second as f64 * self.config.burst_factor,
            refill_rate: self.config.max_tx_per_second as f64,
            last_refill: AtomicTime::new(now),
        };
        
        RateLimiter {
            client_id: client.clone(),
            request_bucket,
            transaction_bucket: tx_bucket,
            concurrent_requests: AtomicU32::new(0),
            violations: AtomicU32::new(0),
            last_used: AtomicTime::new(now),
            reputation_factor: AtomicF64::new(1.0),
        }
    }
    
    fn is_client_banned(&self, client: &ClientId) -> bool {
        self.banned_clients.read().unwrap().contains(client)
    }
    
    fn ban_client(&self, client: &ClientId) {
        let mut banned = self.banned_clients.write().unwrap();
        banned.insert(client.clone());
        
        // Schedule unban after ban duration
        // In a real implementation, this would use a scheduled task
    }
}

impl TokenBucket {
    fn consume(&self, amount: f64) -> bool {
        // Refill tokens based on elapsed time
        self.refill();
        
        // Try to consume tokens
        let current = self.tokens.load(Ordering::SeqCst);
        if current < amount {
            return false; // Not enough tokens
        }
        
        // Attempt atomic update
        let new_value = current - amount;
        self.tokens.store(new_value, Ordering::SeqCst);
        
        true
    }
    
    fn refill(&self) {
        let now = current_time();
        let last = self.last_refill.load(Ordering::SeqCst);
        
        // Calculate time elapsed since last refill
        let elapsed_seconds = (now - last) as f64 / 1_000_000_000.0; // Convert ns to seconds
        if elapsed_seconds <= 0.0 {
            return;
        }
        
        // Calculate tokens to add
        let new_tokens = elapsed_seconds * self.refill_rate;
        
        // Add tokens up to capacity
        let current = self.tokens.load(Ordering::SeqCst);
        let new_value = (current + new_tokens).min(self.capacity);
        
        self.tokens.store(new_value, Ordering::SeqCst);
        self.last_refill.store(now, Ordering::SeqCst);
    }
}

impl ComplexityAnalyzer for GasComplexityAnalyzer {
    fn calculate_complexity(&self, tx: &Transaction) -> u64 {
        // Simple case: gas limit represents computation complexity
        tx.gas_limit
    }
    
    fn complexity_type(&self) -> &'static str {
        "gas"
    }
}

impl ComplexityAnalyzer for DataSizeComplexityAnalyzer {
    fn calculate_complexity(&self, tx: &Transaction) -> u64 {
        // Data size represents storage complexity
        tx.data.len() as u64
    }
    
    fn complexity_type(&self) -> &'static str {
        "data_size"
    }
}

enum DoSError {
    RateLimitExceeded,
    TransactionRateLimitExceeded,
    ConcurrentRequestLimitExceeded,
    TransactionTooComplex {
        complexity_type: String,
        score: u64,
        max_allowed: u64,
    },
    ClientBanned,
}

enum RequestType {
    General,
    Transaction,
    Query,
}
```

**Design Rationale**:
- **Multi-Level Protection**: Combines rate limiting, complexity analysis, and client reputation
- **Token Bucket Algorithm**: Enables both sustained rate limiting and burst handling
- **Dynamic Rate Adjustment**: Rate limits adjust based on network conditions
- **Ban Mechanism**: Persistent attackers face escalating consequences

**For Beginners**: DoS (Denial of Service) protection prevents attackers from overwhelming the system with too many transactions or overly complex ones. It's like having bouncers at a club who ensure no single person or group monopolizes the entrance. The system uses "token buckets" that refill over time, allowing legitimate users to send transactions at a reasonable rate while preventing flooding attacks.

[Back to Index](./06-0-transaction-layer-index.md) | [Previous: Parallelization](./06.08-transaction-layer-parallelization.md) | [Next: References](./06.10-transaction-layer-references.md)
