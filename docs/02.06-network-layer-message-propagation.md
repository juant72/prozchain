# 6. Message Propagation

## 6.1 Broadcast Mechanisms
Methods for efficiently distributing messages to multiple peers.

```rust
struct BroadcastManager {
    active_peers: Arc<RwLock<HashMap<PeerId, PeerConnection>>>,
    broadcast_policies: HashMap<Protocol, BroadcastPolicy>,
    recently_broadcast: ExpiringSet<MessageHash>,
}

enum BroadcastPolicy {
    AllPeers,
    RandomSubset { fraction: f32, min_peers: usize },
    ValidatorPriority { validators_first: bool },
    Geographic { prefer_same_region: bool },
}

impl BroadcastManager {
    async fn broadcast_message(&mut self, protocol: Protocol, message: Message) -> Result<()> {
        let message_hash = hash_message(&message);
        
        // Avoid re-broadcasting recently seen messages
        if self.recently_broadcast.contains(&message_hash) {
            return Ok(());
        }
        
        // Determine broadcast policy
        let policy = self.broadcast_policies
            .get(&protocol)
            .unwrap_or(&BroadcastPolicy::AllPeers);
            
        // Select peers based on policy
        let selected_peers = {
            let peers = self.active_peers.read().await;
            let peer_ids: Vec<PeerId> = peers.keys().copied().collect();
            
            match policy {
                BroadcastPolicy::AllPeers => {
                    peer_ids
                },
                BroadcastPolicy::RandomSubset { fraction, min_peers } => {
                    let count = (peer_ids.len() as f32 * fraction).max(*min_peers as f32) as usize;
                    select_random_peers(&peer_ids, count)
                },
                BroadcastPolicy::ValidatorPriority { validators_first } => {
                    select_validators_first(&peer_ids, *validators_first)
                },
                BroadcastPolicy::Geographic { prefer_same_region } => {
                    select_by_region(&peer_ids, *prefer_same_region)
                },
            }
        };
        
        // Send to selected peers
        for peer_id in selected_peers {
            if let Some(conn) = self.active_peers.read().await.get(&peer_id) {
                if let Err(e) = conn.send_message(message.clone()).await {
                    log::debug!("Failed to broadcast to {}: {}", peer_id, e);
                }
            }
        }
        
        // Mark as recently broadcast
        self.recently_broadcast.insert(message_hash);
        
        Ok(())
    }
    
    fn select_random_peers(peers: &[PeerId], count: usize) -> Vec<PeerId> {
        let mut rng = rand::thread_rng();
        let count = count.min(peers.len());
        
        let mut selected = peers.to_vec();
        selected.shuffle(&mut rng);
        selected.truncate(count);
        
        selected
    }
}
```

**Design Rationale**:
- **Configurable Policies**: Different strategies for different message types
- **Deduplication**: Prevents message loops and duplicates
- **Efficiency**: Minimizes unnecessary message transmission
- **Fault Tolerance**: Continues even if some peers are unreachable

**For Beginners**: Broadcast mechanisms are like choosing how to spread news - sometimes you tell everyone (all peers), sometimes just a random subset of friends, sometimes you prioritize certain people, depending on the importance and urgency of the news.

## 6.2 Gossip Protocol
Epidemic-style message propagation for reliable network-wide distribution.

```rust
struct GossipManager {
    known_messages: ExpiringSet<MessageHash>,
    message_cache: LruCache<MessageHash, Vec<u8>>,
    peer_message_tracking: HashMap<PeerId, HashSet<MessageHash>>,
    gossip_factors: GossipFactors,
}

struct GossipFactors {
    fanout: usize,         // Number of peers to propagate to
    rounds: usize,         // How many rounds of propagation
    propagation_delay: Duration, // Delay between rounds
}

impl GossipManager {
    async fn process_incoming_gossip(&mut self, from_peer: PeerId, message: &[u8]) -> Result<bool> {
        let message_hash = hash_bytes(message);
        
        // Check if we've seen this message before
        if self.known_messages.contains(&message_hash) {
            // Track that this peer has this message
            self.peer_message_tracking
                .entry(from_peer)
                .or_default()
                .insert(message_hash);
            
            return Ok(false); // Not new
        }
        
        // Mark as seen and store
        self.known_messages.insert(message_hash);
        self.message_cache.put(message_hash, message.to_vec());
        
        // Track that this peer has this message
        self.peer_message_tracking
            .entry(from_peer)
            .or_default()
            .insert(message_hash);
        
        // Schedule propagation to other peers
        self.schedule_gossip_propagation(message_hash, self.gossip_factors.rounds);
        
        Ok(true) // New message
    }
    
    async fn schedule_gossip_propagation(&mut self, message_hash: MessageHash, rounds: usize) {
        if rounds == 0 {
            return;
        }
        
        // Clone necessary data for the async task
        let message_data = match self.message_cache.get(&message_hash) {
            Some(data) => data.clone(),
            None => return,
        };
        
        let fanout = self.gossip_factors.fanout;
        let propagation_delay = self.gossip_factors.propagation_delay;
        let peers = self.select_gossip_peers(message_hash, fanout);
        
        // Spawn propagation task
        tokio::spawn(async move {
            // Wait for propagation delay
            tokio::time::sleep(propagation_delay).await;
            
            // Propagate to selected peers
            for peer in peers {
                if let Err(e) = peer.send_gossip(&message_data).await {
                    log::debug!("Gossip propagation failed to {}: {}", peer.id(), e);
                }
            }
            
            // Schedule next round with one fewer round
            self.schedule_gossip_propagation(message_hash, rounds - 1).await;
        });
    }
    
    fn select_gossip_peers(&self, message_hash: MessageHash, count: usize) -> Vec<PeerConnection> {
        // Find peers that haven't seen this message yet
        let mut candidate_peers = Vec::new();
        
        for (peer_id, connection) in &self.active_peers {
            if let Some(known_messages) = self.peer_message_tracking.get(peer_id) {
                if !known_messages.contains(&message_hash) {
                    candidate_peers.push(connection.clone());
                }
            } else {
                // No tracking information, assume they haven't seen it
                candidate_peers.push(connection.clone());
            }
        }
        
        // Select random subset
        let mut rng = rand::thread_rng();
        candidate_peers.shuffle(&mut rng);
        candidate_peers.truncate(count);
        
        candidate_peers
    }
}
```

**Design Rationale**:
- **Epidemic Model**: Information spreads exponentially through the network
- **Peer Knowledge Tracking**: Avoids sending gossip to peers that already have it
- **Staggered Propagation**: Prevents network congestion
- **Self-Limiting**: Naturally stops propagating as information saturates the network

**For Beginners**: The gossip protocol works like spreading rumors in a social network - you tell a few people, they each tell a few more people, and so on, until everyone knows. The system also tracks who already knows what to avoid telling people the same thing twice.

## 6.3 Transaction Propagation Optimization
Specialized methods for efficiently propagating transaction information.

```rust
struct TransactionPropagator {
    mempool: Arc<Mempool>,
    seen_transactions: ExpiringSet<TransactionHash>,
    full_tx_peers: HashSet<PeerId>,
    compact_announcements: bool,
}

enum TransactionAnnouncement {
    Full(Transaction),
    Compact {
        hashes: Vec<TransactionHash>,
        origin: PeerId,
    },
}

impl TransactionPropagator {
    async fn propagate_transaction(&mut self, transaction: Transaction) -> Result<()> {
        let tx_hash = transaction.hash();
        
        // Check if already seen
        if self.seen_transactions.contains(&tx_hash) {
            return Ok(());
        }
        
        // Add to mempool
        self.mempool.add_transaction(transaction.clone())?;
        
        // Mark as seen
        self.seen_transactions.insert(tx_hash);
        
        // Propagate to peers that want full transactions
        for peer_id in &self.full_tx_peers {
            if let Some(peer) = self.get_peer_connection(peer_id) {
                let msg = TransactionAnnouncement::Full(transaction.clone());
                peer.send_message(msg.into()).await?;
            }
        }
        
        // Compact announcements for other peers
        if self.compact_announcements {
            let compact_hashes = vec![tx_hash];
            let origin = self.local_peer_id;
            let msg = TransactionAnnouncement::Compact { 
                hashes: compact_hashes, 
                origin,
            };
            
            // Get peers not in full_tx_peers
            let compact_peers: Vec<_> = self.active_peers
                .iter()
                .filter(|&peer_id| !self.full_tx_peers.contains(peer_id))
                .collect();
                
            // Send to those peers
            for peer_id in compact_peers {
                if let Some(peer) = self.get_peer_connection(peer_id) {
                    peer.send_message(msg.clone().into()).await?;
                }
            }
        }
        
        Ok(())
    }
    
    async fn handle_compact_announcement(&mut self, hashes: Vec<TransactionHash>, origin: PeerId) -> Result<()> {
        let mut unknown_hashes = Vec::new();
        
        // Filter for transactions we don't have
        for hash in hashes {
            if !self.seen_transactions.contains(&hash) && !self.mempool.contains(&hash)? {
                unknown_hashes.push(hash);
            }
        }
        
        if !unknown_hashes.is_empty() {
            // Request unknown transactions from the origin
            if let Some(peer) = self.get_peer_connection(&origin) {
                let request = TransactionRequest {
                    hashes: unknown_hashes,
                };
                peer.send_message(request.into()).await?;
            }
        }
        
        Ok(())
    }
}
```

**Design Rationale**:
- **Compact Announcements**: Hash-only announcements reduce bandwidth
- **Pull Model**: Peers request only transactions they don't have
- **Peer Preferences**: Some peers receive full transactions automatically
- **Deduplication**: Prevents transaction spam and loops

**For Beginners**: Transaction propagation optimization is like sending headlines rather than full articles - we tell peers "we have these transactions" first, and they can request the full details of only the ones they don't already know about, saving bandwidth.

## 6.4 Block Propagation Optimization
Techniques for efficiently propagating blocks.

```rust
struct BlockPropagator {
    chain: Arc<Blockchain>,
    seen_blocks: ExpiringSet<BlockHash>,
    compact_blocks_enabled: bool,
}

enum BlockAnnouncement {
    FullBlock(Block),
    CompactBlock {
        header: BlockHeader,
        short_ids: Vec<ShortTransactionId>,
        missing_transaction_hashes: Vec<TransactionHash>,
    },
    HeaderOnly {
        header: BlockHeader,
    },
}

impl BlockPropagator {
    async fn propagate_block(&mut self, block: Block) -> Result<()> {
        let block_hash = block.hash();
        
        // Check if already seen
        if self.seen_blocks.contains(&block_hash) {
            return Ok(());
        }
        
        // Add to blockchain
        self.chain.add_block(block.clone())?;
        
        // Mark as seen
        self.seen_blocks.insert(block_hash);
        
        // Group peers by announcement type preference
        let (full_block_peers, compact_peers, header_peers) = self.group_peers_by_preference();
        
        // Prepare different announcement formats
        let full_block_msg = BlockAnnouncement::FullBlock(block.clone());
        
        let compact_block = if self.compact_blocks_enabled {
            Some(self.create_compact_block(&block)?)
        } else {
            None
        };
        
        let header_only_msg = BlockAnnouncement::HeaderOnly {
            header: block.header.clone(),
        };
        
        // Send full blocks
        for peer_id in &full_block_peers {
            if let Some(peer) = self.get_peer_connection(peer_id) {
                peer.send_message(full_block_msg.clone().into()).await?;
            }
        }
        
        // Send compact blocks
        if let Some(compact_msg) = &compact_block {
            for peer_id in &compact_peers {
                if let Some(peer) = self.get_peer_connection(peer_id) {
                    peer.send_message(compact_msg.clone().into()).await?;
                }
            }
        }
        
        // Send headers only
        for peer_id in &header_peers {
            if let Some(peer) = self.get_peer_connection(peer_id) {
                peer.send_message(header_only_msg.clone().into()).await?;
            }
        }
        
        Ok(())
    }
    
    fn create_compact_block(&self, block: &Block) -> Result<BlockAnnouncement> {
        // Create short IDs for transactions likely to be in peer mempools
        let mut short_ids = Vec::with_capacity(block.transactions.len());
        let mut missing_hashes = Vec::new();
        
        for tx in &block.transactions {
            let tx_hash = tx.hash();
            let mempool_prevalence = self.estimate_transaction_prevalence(&tx_hash);
            
            if mempool_prevalence > COMPACT_BLOCK_PREVALENCE_THRESHOLD {
                // Likely in peer mempools, use short ID
                short_ids.push(create_short_transaction_id(&tx_hash));
            } else {
                // Unlikely to be in peer mempools, include full hash
                missing_hashes.push(tx_hash);
            }
        }
        
        Ok(BlockAnnouncement::CompactBlock {
            header: block.header.clone(),
            short_ids,
            missing_transaction_hashes: missing_hashes,
        })
    }
    
    async fn handle_compact_block(&mut self, announcement: BlockAnnouncement) -> Result<Option<Block>> {
        if let BlockAnnouncement::CompactBlock { header, short_ids, missing_transaction_hashes } = announcement {
            // Rebuild block from mempool transactions and missing ones
            let mut transactions = Vec::with_capacity(short_ids.len() + missing_transaction_hashes.len());
            let mut missing_short_ids = Vec::new();
            
            // Try to reconstruct from mempool
            for short_id in &short_ids {
                if let Some(tx) = self.lookup_transaction_by_short_id(short_id) {
                    transactions.push(tx);
                } else {
                    missing_short_ids.push(*short_id);
                }
            }
            
            // If we're missing any, request them from peers
            if !missing_short_ids.is_empty() {
                let missing_txs = self.request_missing_transactions(&missing_short_ids).await?;
                transactions.extend(missing_txs);
            }
            
            // Request explicitly missing transactions
            let explicit_missing_txs = self.request_transactions(&missing_transaction_hashes).await?;
            transactions.extend(explicit_missing_txs);
            
            // If we have all transactions, construct and return the block
            if transactions.len() == short_ids.len() + missing_transaction_hashes.len() {
                let block = Block {
                    header,
                    transactions,
                };
                
                // Verify block integrity
                if !verify_block_integrity(&block) {
                    return Err(Error::InvalidBlockReconstruction);
                }
                
                return Ok(Some(block));
            }
        }
        
        // Couldn't fully reconstruct the block
        Ok(None)
    }
}
```

**Design Rationale**:
- **Compact Blocks**: Avoids re-transmitting transactions already in peer mempools
- **Headers First**: Some peers only need headers for light validation
- **Peer Preferences**: Different propagation strategies for different peer types
- **Progressive Enhancement**: Falls back to full blocks when necessary

**For Beginners**: Block propagation optimization is like sending an inventory list instead of shipping the entire warehouse - peers can check what transactions they already have and only request the missing ones, dramatically reducing the data needed to share new blocks.

[Back to Index](./02-0-network-layer-index.md) | [Previous: Message Protocols](./02.05-network-layer-message-protocols.md) | [Next: Network Security](./02.07-network-layer-security.md)
