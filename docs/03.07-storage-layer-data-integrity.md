# 7. Data Integrity

## 7.1 Merkle Trees
Cryptographic data structures that efficiently verify data integrity.

```rust
struct MerkleTree {
    depth: usize,
    nodes: Vec<Hash256>,
    leaves_count: usize,
}

impl MerkleTree {
    fn new(leaves: &[Hash256]) -> Self {
        let leaves_count = leaves.len();
        let depth = calculate_tree_depth(leaves_count);
        
        // Calculate total number of nodes in the tree
        let nodes_count = (1 << (depth + 1)) - 1;
        let mut nodes = vec![Hash256::default(); nodes_count];
        
        // Copy leaf nodes
        for (i, leaf) in leaves.iter().enumerate() {
            nodes[nodes_count - leaves_count + i] = *leaf;
        }
        
        // Generate tree from leaves to root
        Self::generate_tree_nodes(&mut nodes, depth, leaves_count);
        
        MerkleTree {
            depth,
            nodes,
            leaves_count,
        }
    }
    
    fn generate_tree_nodes(nodes: &mut [Hash256], depth: usize, leaves_count: usize) {
        let leaf_start_idx = (1 << depth) - 1;
        
        // Iterate from bottom to top, computing parent nodes
        for current_depth in (0..depth).rev() {
            let start_idx = (1 << current_depth) - 1;
            let end_idx = (1 << (current_depth + 1)) - 2;
            let child_start_idx = (1 << (current_depth + 1)) - 1;
            
            for parent_idx in start_idx..=end_idx {
                let left_child_idx = child_start_idx + 2 * (parent_idx - start_idx);
                let right_child_idx = left_child_idx + 1;
                
                // Check if we're past the leaf nodes
                let left_exists = left_child_idx < nodes.len();
                let right_exists = right_child_idx < nodes.len() && 
                                  (right_child_idx - leaf_start_idx < leaves_count);
                
                if left_exists && right_exists {
                    // Hash both children
                    let mut combined = Vec::with_capacity(64);
                    combined.extend_from_slice(nodes[left_child_idx].as_bytes());
                    combined.extend_from_slice(nodes[right_child_idx].as_bytes());
                    nodes[parent_idx] = hash_bytes(&combined);
                } else if left_exists {
                    // Only left child exists, propagate its hash
                    nodes[parent_idx] = nodes[left_child_idx];
                }
            }
        }
    }
    
    fn get_root(&self) -> Hash256 {
        self.nodes[0]
    }
    
    fn generate_proof(&self, leaf_index: usize) -> Vec<Hash256> {
        if leaf_index >= self.leaves_count {
            return Vec::new();  // Invalid index
        }
        
        let mut proof = Vec::with_capacity(self.depth);
        let mut current_idx = (1 << self.depth) - 1 + leaf_index;
        
        for _ in 0..self.depth {
            // Determine if current_idx is a left or right child
            let is_left = current_idx % 2 == 0;
            
            // Add sibling to proof
            let sibling_idx = if is_left { current_idx - 1 } else { current_idx + 1 };
            
            if sibling_idx < self.nodes.len() {
                proof.push(self.nodes[sibling_idx]);
            } else {
                // If sibling is out of bounds, use a default hash
                proof.push(Hash256::default());
            }
            
            // Move up to parent
            current_idx = (current_idx - 1) / 2;
        }
        
        proof
    }
    
    fn verify_proof(root: Hash256, leaf: Hash256, index: usize, proof: &[Hash256]) -> bool {
        let mut current_hash = leaf;
        let mut current_index = index;
        
        for sibling in proof {
            let (left, right) = if current_index % 2 == 0 {
                (current_hash, *sibling)  // Current is left child
            } else {
                (*sibling, current_hash)  // Current is right child
            };
            
            // Compute parent hash
            let mut combined = Vec::with_capacity(64);
            combined.extend_from_slice(left.as_bytes());
            combined.extend_from_slice(right.as_bytes());
            current_hash = hash_bytes(&combined);
            
            // Move up to parent index
            current_index /= 2;
        }
        
        current_hash == root
    }
}
```

**Design Rationale**:
- **Efficient Proofs**: Logarithmic-sized proofs relative to data size
- **Compact Representation**: Minimizes storage requirements
- **Single-Pass Generation**: Builds tree efficiently in one pass
- **Zero-Copy Verification**: Minimizes memory allocations during proof verification

**For Beginners**: Merkle trees are like a sophisticated fingerprinting system. They let you create a single "master fingerprint" (the root hash) for a large set of data. Then, you can prove that a specific piece of data belongs to that set by providing just a small proof, without needing to check every piece.

## 7.2 Verification Process
Validates data integrity throughout the storage layer.

```rust
struct DataVerifier {
    storage: Arc<StorageEngine>,
    verification_config: VerificationConfig,
}

struct VerificationConfig {
    block_batch_size: usize,
    verify_transactions: bool,
    verify_state: bool,
    verify_receipts: bool,
    parallelism: usize,
}

impl DataVerifier {
    async fn verify_chain_segment(&self, from_height: BlockHeight, to_height: BlockHeight) -> Result<VerificationReport> {
        log::info!("Verifying chain segment from height {} to {}", from_height, to_height);
        
        let mut report = VerificationReport::new(from_height, to_height);
        let mut current_height = from_height;
        
        while current_height <= to_height {
            // Determine batch end
            let batch_end = (current_height + self.verification_config.block_batch_size - 1)
                .min(to_height);
                
            // Verify batch of blocks
            let batch_report = self.verify_blocks_batch(current_height, batch_end).await?;
            report.merge(batch_report);
            
            // Move to next batch
            current_height = batch_end + 1;
        }
        
        log::info!("Chain segment verification complete: {:?}", report.summary());
        
        Ok(report)
    }
    
    async fn verify_blocks_batch(&self, start_height: BlockHeight, end_height: BlockHeight) -> Result<VerificationReport> {
        let mut report = VerificationReport::new(start_height, end_height);
        let mut tasks = Vec::new();
        
        // Create verification tasks
        for height in start_height..=end_height {
            let storage = self.storage.clone();
            let config = self.verification_config.clone();
            
            let task = tokio::spawn(async move {
                let block_result = verify_block_at_height(storage, height, &config).await;
                (height, block_result)
            });
            
            tasks.push(task);
        }
        
        // Collect results
        for task in tasks {
            let (height, result) = task.await?;
            
            match result {
                Ok(integrity) => {
                    report.add_block_verification(height, true);
                    
                    if !integrity.state_valid {
                        report.add_state_error(height, integrity.state_error);
                    }
                    
                    if !integrity.transactions_valid {
                        report.add_transaction_error(height, integrity.transaction_error);
                    }
                    
                    if !integrity.receipts_valid {
                        report.add_receipt_error(height, integrity.receipt_error);
                    }
                },
                Err(e) => {
                    report.add_block_verification(height, false);
                    report.add_block_error(height, e.to_string());
                }
            }
        }
        
        Ok(report)
    }
    
    async fn verify_state_roots(&self, height: BlockHeight) -> Result<bool> {
        // Retrieve block at height
        let block = self.storage.block_store.get_block_by_height(height)?;
        
        // Get state root recorded in block
        let block_state_root = block.header.state_root;
        
        // Compute state root by applying block transactions
        let computed_state_root = self.compute_state_root_at_height(height)?;
        
        // Compare roots
        if block_state_root != computed_state_root {
            log::error!("State root mismatch at height {}. Block: {}, Computed: {}", 
                       height, block_state_root, computed_state_root);
            return Ok(false);
        }
        
        Ok(true)
    }
    
    fn verify_transaction_inclusion(&self, tx_hash: &TransactionHash) -> Result<bool> {
        // Lookup transaction location
        let location = self.storage.transaction_index.get_transaction_location(tx_hash)?;
        
        // Get block containing transaction
        let block = self.storage.block_store.get_block(&location.block_hash)?;
        
        // Check if transaction is at expected index
        if location.index >= block.transactions.len() as u32 {
            return Ok(false);
        }
        
        // Verify transaction hash
        let tx = &block.transactions[location.index as usize];
        let actual_hash = tx.hash();
        
        if &actual_hash != tx_hash {
            return Ok(false);
        }
        
        // Verify inclusion in transaction root via Merkle proof
        let tx_hashes: Vec<_> = block.transactions.iter().map(|tx| tx.hash()).collect();
        let tree = MerkleTree::new(&tx_hashes);
        
        let root = tree.get_root();
        if root != block.header.transactions_root {
            return Ok(false);
        }
        
        Ok(true)
    }
}

async fn verify_block_at_height(
    storage: Arc<StorageEngine>,
    height: BlockHeight,
    config: &VerificationConfig
) -> Result<BlockIntegrity> {
    let mut integrity = BlockIntegrity::default();
    
    // Get block at height
    let block = storage.block_store.get_block_by_height(height)?;
    
    // Verify transactions
    if config.verify_transactions {
        let tx_hashes: Vec<_> = block.transactions.iter().map(|tx| tx.hash()).collect();
        let tree = MerkleTree::new(&tx_hashes);
        
        integrity.transactions_valid = tree.get_root() == block.header.transactions_root;
        if !integrity.transactions_valid {
            integrity.transaction_error = "Transaction root mismatch".to_string();
        }
    }
    
    // Verify receipts if available
    if config.verify_receipts {
        // Get receipts for this block
        let mut receipts = Vec::new();
        for tx in &block.transactions {
            if let Some(receipt) = storage.receipt_store.get_receipt(&tx.hash())? {
                receipts.push(receipt);
            } else {
                integrity.receipts_valid = false;
                integrity.receipt_error = "Missing receipt".to_string();
                break;
            }
        }
        
        // Verify receipts root if we have all receipts
        if receipts.len() == block.transactions.len() {
            let receipt_hashes: Vec<_> = receipts.iter().map(|r| hash_receipt(r)).collect();
            let tree = MerkleTree::new(&receipt_hashes);
            
            integrity.receipts_valid = tree.get_root() == block.header.receipts_root;
            if !integrity.receipts_valid {
                integrity.receipt_error = "Receipts root mismatch".to_string();
            }
        }
    }
    
    // Verify state root
    if config.verify_state {
        let state_reconstructor = StateReconstructor::new(storage.clone());
        
        // Get previous block's state root
        let parent_hash = block.header.parent_hash;
        let parent_block = storage.block_store.get_block(&parent_hash)?;
        let parent_state_root = parent_block.header.state_root;
        
        // Apply transactions to compute state root
        let computed_state_root = state_reconstructor.compute_state_root(
            &parent_state_root,
            &block.transactions
        )?;
        
        integrity.state_valid = computed_state_root == block.header.state_root;
        if !integrity.state_valid {
            integrity.state_error = format!(
                "State root mismatch: expected {}, got {}",
                block.header.state_root,
                computed_state_root
            );
        }
    }
    
    Ok(integrity)
}
```

**Design Rationale**:
- **Parallel Verification**: Distributes verification work across CPU cores
- **Configurable Scope**: Different verification levels for different needs
- **Detailed Reporting**: Captures specific issues for troubleshooting
- **Incremental Verification**: Can verify specific blocks or ranges

**For Beginners**: Data verification is like having quality control inspectors that check the integrity of your blockchain data. They verify that all the cryptographic proofs are valid and that the data hasn't been corrupted or tampered with.

## 7.3 Corruption Detection and Recovery
Systems for detecting and repairing data corruption.

```rust
struct CorruptionDetector {
    storage: Arc<StorageEngine>,
    scan_config: CorruptionScanConfig,
    repair_manager: RepairManager,
}

struct CorruptionScanConfig {
    scan_interval: Duration,
    batch_size: usize,
    checksum_validation: bool,
    headers_only: bool,
    randomized_sampling: bool,
}

impl CorruptionDetector {
    async fn run_periodic_scan(&self) -> Result<ScanResults> {
        // Get current chain height
        let current_height = self.storage.get_current_height()?;
        
        // Determine scan strategy
        let heights_to_scan = if self.scan_config.randomized_sampling {
            self.select_random_heights(current_height)
        } else {
            self.select_sequential_heights(current_height)
        };
        
        // Scan selected blocks
        let mut results = ScanResults::default();
        
        for height_batch in heights_to_scan.chunks(self.scan_config.batch_size) {
            let batch_results = self.scan_block_batch(height_batch).await?;
            results.merge(batch_results);
        }
        
        // Trigger repairs if corruption detected
        if results.has_corruption() {
            log::warn!("Corruption detected in {} blocks", results.corrupt_blocks.len());
            
            if self.repair_manager.auto_repair_enabled() {
                self.repair_manager.repair_corrupted_blocks(&results.corrupt_blocks).await?;
            }
        }
        
        Ok(results)
    }
    
    fn select_random_heights(&self, max_height: BlockHeight) -> Vec<BlockHeight> {
        let mut rng = rand::thread_rng();
        let sample_count = (max_height as f64 * self.scan_config.sample_ratio) as usize;
        
        let mut heights = Vec::with_capacity(sample_count);
        for _ in 0..sample_count {
            let height = rng.gen_range(0..=max_height);
            heights.push(height);
        }
        
        heights
    }
    
    async fn scan_block_batch(&self, heights: &[BlockHeight]) -> Result<ScanResults> {
        let mut results = ScanResults::default();
        let mut tasks = Vec::new();
        
        // Create scan tasks
        for &height in heights {
            let storage = self.storage.clone();
            let checksum_validation = self.scan_config.checksum_validation;
            let headers_only = self.scan_config.headers_only;
            
            let task = tokio::spawn(async move {
                let result = scan_block_at_height(storage, height, checksum_validation, headers_only).await;
                (height, result)
            });
            
            tasks.push(task);
        }
        
        // Collect results
        for task in tasks {
            let (height, result) = task.await?;
            
            match result {
                Ok(integrity_check) => {
                    if !integrity_check.is_valid() {
                        results.add_corrupt_block(height, integrity_check.corruption_details);
                    }
                },
                Err(e) => {
                    results.add_corrupt_block(height, format!("Scan error: {}", e));
                }
            }
        }
        
        Ok(results)
    }
}

struct RepairManager {
    storage: Arc<StorageEngine>,
    network: Arc<NetworkService>,
    auto_repair: bool,
    repair_strategies: Vec<RepairStrategy>,
}

impl RepairManager {
    async fn repair_corrupted_blocks(&self, corrupt_blocks: &[(BlockHeight, String)]) -> Result<RepairResults> {
        let mut results = RepairResults::default();
        
        for &(height, ref error) in corrupt_blocks {
            log::info!("Attempting to repair block at height {} ({})", height, error);
            
            // Try each repair strategy until one succeeds
            for strategy in &self.repair_strategies {
                match self.try_repair_with_strategy(height, strategy).await {
                    Ok(()) => {
                        results.add_repaired_block(height, strategy.name());
                        break;
                    },
                    Err(e) => {
                        log::debug!("Repair strategy {} failed for block {}: {}", 
                                  strategy.name(), height, e);
                                  
                        // Try next strategy
                        continue;
                    }
                }
            }
        }
        
        Ok(results)
    }
    
    async fn try_repair_with_strategy(&self, height: BlockHeight, strategy: &RepairStrategy) -> Result<()> {
        match strategy {
            RepairStrategy::LocalRecalculation => {
                // Try to repair by recalculating from existing data
                self.repair_by_local_recalculation(height).await
            },
            RepairStrategy::PeerRecovery => {
                // Try to recover the block from peers
                self.repair_by_peer_recovery(height).await
            },
            RepairStrategy::BackupRestoration { backup_path } => {
                // Try to restore from backup
                self.repair_from_backup(height, backup_path).await
            },
            RepairStrategy::StateRegeneration => {
                // Try to regenerate state by replaying transactions
                self.repair_by_state_regeneration(height).await
            }
        }
    }
    
    async fn repair_by_peer_recovery(&self, height: BlockHeight) -> Result<()> {
        // Get reliable peers
        let peers = self.network.get_reliable_peers()?;
        if peers.is_empty() {
            return Err(Error::NoPeersAvailable);
        }
        
        // Try to fetch block from peers
        for peer in peers {
            match self.fetch_block_from_peer(peer, height).await {
                Ok(block) => {
                    // Verify the block
                    if self.verify_block_integrity(&block).is_err() {
                        continue; // Try next peer
                    }
                    
                    // Store the recovered block
                    self.storage.block_store.store_block(&block)?;
                    
                    return Ok(());
                },
                Err(_) => continue, // Try next peer
            }
        }
        
        Err(Error::BlockRecoveryFailed(height))
    }
    
    async fn repair_by_state_regeneration(&self, height: BlockHeight) -> Result<()> {
        // Find a good snapshot before this height
        let snapshot_height = self.find_valid_snapshot_before(height)?;
        
        // Replay blocks from snapshot to target height
        let state_root = self.storage.state_database.get_state_root_at_height(snapshot_height)?;
        let mut state_reconstructor = StateReconstructor::new(self.storage.clone());
        
        // Initialize state from snapshot
        state_reconstructor.initialize_from_root(&state_root)?;
        
        // Apply each block's transactions up to the target height
        for block_height in (snapshot_height + 1)..=height {
            let block = self.storage.block_store.get_block_by_height(block_height)?;
            state_reconstructor.apply_block(&block)?;
        }
        
        // Update the state root for the target height
        self.storage.state_database.store_state_root_at_height(
            height,
            state_reconstructor.state_root()
        )?;
        
        Ok(())
    }
}
```

**Design Rationale**:
- **Proactive Scanning**: Periodically checks data integrity before issues arise
- **Layered Recovery**: Multiple strategies for different corruption scenarios
- **Network Recovery**: Leverages peer data to recover corrupted blocks
- **Minimal Downtime**: Repairs while the system continues to operate

**For Beginners**: Corruption detection and recovery is like having an immune system for your blockchain data. It continuously scans for problems, and when it finds corrupted data, it has several strategies to fix it - from local repairs to asking other nodes for help.

[Back to Index](./03-0-storage-layer-index.md) | [Previous: Pruning Mechanisms](./03.06-storage-layer-pruning.md) | [Next: Performance Optimization](./03.08-storage-layer-performance.md)
